# -*- coding: utf-8 -*-
"""Fetal Health Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fMISGRFwJXHRwheNygvios0sN0xK9MmN
"""

# importing libraries
import pandas as pd
import numpy as np
import pickle
import matplotlib.pyplot as plt
import seaborn as sns
import statistics as stats

from sklearn.decomposition import PCA
from collections import Counter

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import f1_score, precision_score, accuracy_score, recall_score, classification_report

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.multiclass import OneVsOneClassifier

# to supress warnings
import warnings
warnings.filterwarnings("ignore")

data = pd.read_csv("../dataset/fetal_health.csv")
data.head()

"""## Exploratory Data Analysis"""

data.shape

data.describe()

data.isnull().sum()

"""About target value
* 1 = Normal
* 2 = Suspect
* 3 = Pathological
"""

df = data.copy(deep=True)
df.head()

df['fetal_health'] = df['fetal_health'].replace({
        1.0: "NORMAL",
        2.0: "SUSPECT",
        3.0: "PATHOLOGICAL"
    })

df.head()

sns.countplot(x=df['fetal_health'])
plt.show()

plt.pie(
    df['fetal_health'].value_counts(),
    autopct='%.2f%%',
    labels=['NORMAL','SUSPECT','PATHOLOGICAL']
)

plt.title("Class Distribution")
plt.show()

# visualizing dataset using PCA
pca = PCA(n_components=2)
x_pca = pca.fit_transform(df.iloc[:,:-1])
sns.scatterplot(x_pca[:,0],x_pca[:,1],hue=df.iloc[:,-1])
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.title("Visualizing dataset")
plt.show()

plt.figure(figsize=(25, 15))

for i, col in enumerate(df.columns):
    plt.subplot(4, 6, i+1)
    sns.histplot(data = df[col])
    plt.title(col)

plt.tight_layout()
plt.show()

plt.figure(figsize=(24, 20))
sns.heatmap(df.corr(), annot=True)
plt.title("Correlation Matrix")
plt.show()

def preprocess(data):
    df = data.copy(deep=True)

    # X and y split and dropping 2 features
    df = df.drop(['histogram_mode','histogram_median'],axis=1)
    X = df.drop('fetal_health',axis=1)
    y = df['fetal_health']

    # train test split
    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)

    # standard scaling
    sc = StandardScaler()
    sc.fit(X_train)
    X_train = pd.DataFrame(sc.transform(X_train), index=X_train.index, columns=X_train.columns)
    X_test = pd.DataFrame(sc.transform(X_test), index=X_test.index, columns=X_test.columns)

    return X_train, X_test, y_train, y_test

X_train, X_test, y_train, y_test = preprocess(df)

X_train.head()

"""## Defining metric (recall)"""

def recall_cal(y_true,y_pred):
    recall_df = pd.DataFrame(zip(['NORMAL','SUSPECT','PATHOLOGICAL'],
                                 recall_score(y_true,y_pred,average=None)),
                             columns=['Class','Recall Score'])
    recall_df.loc[len(recall_df.index)] = ['MACRO RECALL',recall_score(y_true,y_pred,average='macro')]
    return recall_df

"""### Baseline Model 1: Mode"""

class bs_mode:

    def __init__(self):
        self.mode = None

    def fit(self,X,y):
        self.mode = stats.mode(y)

    def predict(self,X):
        y_pred = [self.mode for i in range(X.shape[0])]
        return np.array(y_pred)

m1 = bs_mode()
m1.fit(X_train,y_train)
y_pred_train_mode = m1.predict(X_train)
y_pred_test_mode = m1.predict(X_test)

y_pred_train_mode

y_pred_test_mode[0:10]

print("TRAINING SET RESULTS")
print("MODEL: Mode")
print("-"*30)
print(recall_cal(y_train,y_pred_train_mode).to_string(index=False))

print("TESTING SET RESULTS")
print("MODEL: Mode")
print("-"*30)
print(recall_cal(y_test,y_pred_test_mode).to_string(index=False))

"""### Baseline Model 2: Logistic Regression"""

m2 = LogisticRegression()
m2.fit(X_train,y_train)
y_pred_train_lr = m2.predict(X_train)
y_pred_test_lr = m2.predict(X_test)

print("TRAINING SET RESULTS")
print("MODEL: Logistic Regression with default params")
print("-"*50)
print(recall_cal(y_train,y_pred_train_lr).to_string(index=False))

print("TESTING SET RESULTS")
print("MODEL: Logistic Regression with default params")
print("-"*50)
print(recall_cal(y_test,y_pred_test_lr).to_string(index=False))

"""## Trying different models

#### Logistic Regression with params changing
"""

m3 = LogisticRegression(class_weight='balanced')
m3.fit(X_train,y_train)
y_pred_train_3 = m3.predict(X_train)
y_pred_test_3 = m3.predict(X_test)

print("TRAINING SET RESULTS")
print("MODEL: Logistic Regression with class_weight='balanced'")
print("-"*50)
print(recall_cal(y_train,y_pred_train_3).to_string(index=False))

print("TESTING SET RESULTS")
print("MODEL: Logistic Regression with class_weight='balanced'")
print("-"*50)
print(recall_cal(y_test,y_pred_test_3).to_string(index=False))

"""#### Logistic Regression with params changing and OVO"""

m4 = OneVsOneClassifier(LogisticRegression(class_weight='balanced'))
m4.fit(X_train,y_train)
y_pred_train_4 = m4.predict(X_train)
y_pred_test_4 = m4.predict(X_test)

print("TRAINING SET RESULTS")
print("MODEL: Logistic Regression with class_weight='balanced' and OVO")
print("-"*50)
print(recall_cal(y_train,y_pred_train_4).to_string(index=False))

print("TESTING SET RESULTS")
print("MODEL: Logistic Regression with class_weight='balanced' and OVO")
print("-"*50)
print(recall_cal(y_test,y_pred_test_4).to_string(index=False))

"""#### SVC with params changing"""

m5 = SVC(class_weight='balanced',decision_function_shape='ovo',kernel='rbf')
m5.fit(X_train,y_train)
y_pred_train_5 = m5.predict(X_train)
y_pred_test_5 = m5.predict(X_test)

print("TRAINING SET RESULTS")
print("MODEL: SVC with class_weight='balanced' and OVO (kernel:rbf)")
print("-"*50)
print(recall_cal(y_train,y_pred_train_5).to_string(index=False))

print("TESTING SET RESULTS")
print("MODEL: MODEL: SVC with class_weight='balanced' and OVO (kernel:rbf)")
print("-"*50)
print(recall_cal(y_test,y_pred_test_5).to_string(index=False))

"""#### DT Classifier with params changing"""

m6 = DecisionTreeClassifier(random_state=28,max_depth=7,min_samples_split=10)
m6.fit(X_train,y_train)
y_pred_train_6 = m6.predict(X_train)
y_pred_test_6 = m6.predict(X_test)

print("TRAINING SET RESULTS")
print("MODEL: DT with max_depth=7,min_samples_split=10")
print("-"*50)
print(recall_cal(y_train,y_pred_train_6).to_string(index=False))

print("TESTING SET RESULTS")
print("MODEL: DT with max_depth=7,min_samples_split=10")
print("-"*50)
print(recall_cal(y_test,y_pred_test_6).to_string(index=False))

"""#### kNN Classifier with params changing"""

m7 = KNeighborsClassifier(n_neighbors=5,weights='distance')
m7.fit(X_train,y_train)
y_pred_train_7 = m7.predict(X_train)
y_pred_test_7 = m7.predict(X_test)

print("TRAINING SET RESULTS")
print("MODEL: kNN (k=5, weights='distance')")
print("-"*50)
print(recall_cal(y_train,y_pred_train_7).to_string(index=False))

print("TESTING SET RESULTS")
print("MODEL: kNN (k=5, weights='distance')")
print("-"*50)
print(recall_cal(y_test,y_pred_test_7).to_string(index=False))

"""#### Random Forest Classifier with params changing"""

m8 = RandomForestClassifier(random_state=28,n_estimators=65,class_weight='balanced',criterion='gini',min_samples_leaf=15)
m8.fit(X_train,y_train)
y_pred_train_8 = m8.predict(X_train)
y_pred_test_8 = m8.predict(X_test)

print("TRAINING SET RESULTS")
print("MODEL: Random Forest Classifier (n_estimators=65,class_weight='balanced',criterion='gini',min_samples_leaf=15)")
print("-"*50)
print(recall_cal(y_train,y_pred_train_8).to_string(index=False))

print("TESTING SET RESULTS")
print("MODEL: Random Forest Classifier (n_estimators=65,class_weight='balanced',criterion='gini',min_samples_leaf=15)")
print("-"*50)
print(recall_cal(y_test,y_pred_test_8).to_string(index=False))

"""#### AdaBoost Classifier with params changing"""

m9 = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(random_state=28,
                                                              max_depth=7,
                                                              min_samples_split=10),
                        random_state=28,n_estimators=40,learning_rate=1.5)
m9.fit(X_train,y_train)
y_pred_train_9 = m9.predict(X_train)
y_pred_test_9 = m9.predict(X_test)

print("TRAINING SET RESULTS")
print("MODEL: AdaBoostClassifier")
print("params: base_estimator=DecisionTreeClassifier(max_depth=7,min_samples_split=10),n_estimators=40,learning_rate=1.5")
print("-"*50)
print(recall_cal(y_train,y_pred_train_9).to_string(index=False))

print("TESTING SET RESULTS")
print("MODEL: AdaBoostClassifier")
print("params: base_estimator=DecisionTreeClassifier(max_depth=7,min_samples_split=10),n_estimators=40,learning_rate=1.5")
print("-"*50)
print(recall_cal(y_test,y_pred_test_9).to_string(index=False))

"""### How to classify final point?
Using 3 models and then using majority voting
Models Used
* SVC with class_weight='balanced' and OVO (kernel:rbf)
* Random Forest Classifier (n_estimators=65,class_weight='balanced',criterion='gini',min_samples_leaf=15)
* AdaBoostClassifier with base_estimator=DecisionTreeClassifier(max_depth=7,min_samples_split=10),n_estimators=40,learning_rate=1.5
* DecisionTreeClassifier(max_depth=7,min_samples_split=10)
"""

pickle.dump(m8, open("../models/fetal_hc_1", 'wb'))
pickle.dump(m5, open("../models/fetal_hc_2", 'wb'))
pickle.dump(m6, open("../models/fetal_hc_3", 'wb'))
pickle.dump(m9, open("../models/fetal_hc_4", 'wb'))

def pred_final(X):
    lm1 = pickle.load(open("../models/fetal_hc_1", 'rb'))
    lm2 = pickle.load(open("../models/fetal_hc_2", 'rb'))
    lm3 = pickle.load(open("../models/fetal_hc_3", 'rb'))
    lm4 = pickle.load(open("../models/fetal_hc_4", 'rb'))
    y_pred = []
    yp1 = lm1.predict(X)
    yp2 = lm2.predict(X)
    yp3 = lm3.predict(X)
    yp4 = lm4.predict(X)
    for i,j,k,l in zip(yp1,yp2,yp3,yp4):
        li = [i,j,k,l]
        li = Counter(li)
        li = {k: v for k, v in sorted(li.items(), key=lambda item: item[1],reverse=True)}
        y_pred.append(list(li.keys())[0])
    return np.array(y_pred)

y_pred_train_fm = pred_final(X_train)
y_pred_test_fm = pred_final(X_test)

print("TRAINING SET RESULTS")
print("-"*50)
print(recall_cal(y_train,y_pred_train_fm).to_string(index=False))

print("TESTING SET RESULTS")
print("-"*50)
print(recall_cal(y_test,y_pred_test_fm).to_string(index=False))

print("TRAIN CLASSIFICATION REPORT")
print("-"*50)
print(classification_report(y_train,y_pred_train_fm))

print("TEST CLASSIFICATION REPORT")
print("-"*50)
print(classification_report(y_test,y_pred_test_fm))

X_train.columns

X_train.shape

X_train.info()

scobj = StandardScaler()
scobj.fit(X_train)

pickle.dump(scobj,open("../models/StandardScalerObj",'wb'))